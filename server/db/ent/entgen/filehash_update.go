// Code generated by entc, DO NOT EDIT.

package entgen

import (
	"context"
	"fmt"

	"entgo.io/ent/dialect/sql"
	"entgo.io/ent/dialect/sql/sqlgraph"
	"entgo.io/ent/schema/field"
	"github.com/harmony-development/legato/server/db/ent/entgen/filehash"
	"github.com/harmony-development/legato/server/db/ent/entgen/predicate"
)

// FileHashUpdate is the builder for updating FileHash entities.
type FileHashUpdate struct {
	config
	hooks    []Hook
	mutation *FileHashMutation
}

// Where adds a new predicate for the FileHashUpdate builder.
func (fhu *FileHashUpdate) Where(ps ...predicate.FileHash) *FileHashUpdate {
	fhu.mutation.predicates = append(fhu.mutation.predicates, ps...)
	return fhu
}

// SetHash sets the "hash" field.
func (fhu *FileHashUpdate) SetHash(b []byte) *FileHashUpdate {
	fhu.mutation.SetHash(b)
	return fhu
}

// SetFileid sets the "fileid" field.
func (fhu *FileHashUpdate) SetFileid(s string) *FileHashUpdate {
	fhu.mutation.SetFileid(s)
	return fhu
}

// Mutation returns the FileHashMutation object of the builder.
func (fhu *FileHashUpdate) Mutation() *FileHashMutation {
	return fhu.mutation
}

// Save executes the query and returns the number of nodes affected by the update operation.
func (fhu *FileHashUpdate) Save(ctx context.Context) (int, error) {
	var (
		err      error
		affected int
	)
	if len(fhu.hooks) == 0 {
		affected, err = fhu.sqlSave(ctx)
	} else {
		var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
			mutation, ok := m.(*FileHashMutation)
			if !ok {
				return nil, fmt.Errorf("unexpected mutation type %T", m)
			}
			fhu.mutation = mutation
			affected, err = fhu.sqlSave(ctx)
			mutation.done = true
			return affected, err
		})
		for i := len(fhu.hooks) - 1; i >= 0; i-- {
			mut = fhu.hooks[i](mut)
		}
		if _, err := mut.Mutate(ctx, fhu.mutation); err != nil {
			return 0, err
		}
	}
	return affected, err
}

// SaveX is like Save, but panics if an error occurs.
func (fhu *FileHashUpdate) SaveX(ctx context.Context) int {
	affected, err := fhu.Save(ctx)
	if err != nil {
		panic(err)
	}
	return affected
}

// Exec executes the query.
func (fhu *FileHashUpdate) Exec(ctx context.Context) error {
	_, err := fhu.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (fhu *FileHashUpdate) ExecX(ctx context.Context) {
	if err := fhu.Exec(ctx); err != nil {
		panic(err)
	}
}

func (fhu *FileHashUpdate) sqlSave(ctx context.Context) (n int, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   filehash.Table,
			Columns: filehash.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: filehash.FieldID,
			},
		},
	}
	if ps := fhu.mutation.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if value, ok := fhu.mutation.Hash(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeBytes,
			Value:  value,
			Column: filehash.FieldHash,
		})
	}
	if value, ok := fhu.mutation.Fileid(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: filehash.FieldFileid,
		})
	}
	if n, err = sqlgraph.UpdateNodes(ctx, fhu.driver, _spec); err != nil {
		if _, ok := err.(*sqlgraph.NotFoundError); ok {
			err = &NotFoundError{filehash.Label}
		} else if cerr, ok := isSQLConstraintError(err); ok {
			err = cerr
		}
		return 0, err
	}
	return n, nil
}

// FileHashUpdateOne is the builder for updating a single FileHash entity.
type FileHashUpdateOne struct {
	config
	fields   []string
	hooks    []Hook
	mutation *FileHashMutation
}

// SetHash sets the "hash" field.
func (fhuo *FileHashUpdateOne) SetHash(b []byte) *FileHashUpdateOne {
	fhuo.mutation.SetHash(b)
	return fhuo
}

// SetFileid sets the "fileid" field.
func (fhuo *FileHashUpdateOne) SetFileid(s string) *FileHashUpdateOne {
	fhuo.mutation.SetFileid(s)
	return fhuo
}

// Mutation returns the FileHashMutation object of the builder.
func (fhuo *FileHashUpdateOne) Mutation() *FileHashMutation {
	return fhuo.mutation
}

// Select allows selecting one or more fields (columns) of the returned entity.
// The default is selecting all fields defined in the entity schema.
func (fhuo *FileHashUpdateOne) Select(field string, fields ...string) *FileHashUpdateOne {
	fhuo.fields = append([]string{field}, fields...)
	return fhuo
}

// Save executes the query and returns the updated FileHash entity.
func (fhuo *FileHashUpdateOne) Save(ctx context.Context) (*FileHash, error) {
	var (
		err  error
		node *FileHash
	)
	if len(fhuo.hooks) == 0 {
		node, err = fhuo.sqlSave(ctx)
	} else {
		var mut Mutator = MutateFunc(func(ctx context.Context, m Mutation) (Value, error) {
			mutation, ok := m.(*FileHashMutation)
			if !ok {
				return nil, fmt.Errorf("unexpected mutation type %T", m)
			}
			fhuo.mutation = mutation
			node, err = fhuo.sqlSave(ctx)
			mutation.done = true
			return node, err
		})
		for i := len(fhuo.hooks) - 1; i >= 0; i-- {
			mut = fhuo.hooks[i](mut)
		}
		if _, err := mut.Mutate(ctx, fhuo.mutation); err != nil {
			return nil, err
		}
	}
	return node, err
}

// SaveX is like Save, but panics if an error occurs.
func (fhuo *FileHashUpdateOne) SaveX(ctx context.Context) *FileHash {
	node, err := fhuo.Save(ctx)
	if err != nil {
		panic(err)
	}
	return node
}

// Exec executes the query on the entity.
func (fhuo *FileHashUpdateOne) Exec(ctx context.Context) error {
	_, err := fhuo.Save(ctx)
	return err
}

// ExecX is like Exec, but panics if an error occurs.
func (fhuo *FileHashUpdateOne) ExecX(ctx context.Context) {
	if err := fhuo.Exec(ctx); err != nil {
		panic(err)
	}
}

func (fhuo *FileHashUpdateOne) sqlSave(ctx context.Context) (_node *FileHash, err error) {
	_spec := &sqlgraph.UpdateSpec{
		Node: &sqlgraph.NodeSpec{
			Table:   filehash.Table,
			Columns: filehash.Columns,
			ID: &sqlgraph.FieldSpec{
				Type:   field.TypeInt,
				Column: filehash.FieldID,
			},
		},
	}
	id, ok := fhuo.mutation.ID()
	if !ok {
		return nil, &ValidationError{Name: "ID", err: fmt.Errorf("missing FileHash.ID for update")}
	}
	_spec.Node.ID.Value = id
	if fields := fhuo.fields; len(fields) > 0 {
		_spec.Node.Columns = make([]string, 0, len(fields))
		_spec.Node.Columns = append(_spec.Node.Columns, filehash.FieldID)
		for _, f := range fields {
			if !filehash.ValidColumn(f) {
				return nil, &ValidationError{Name: f, err: fmt.Errorf("entgen: invalid field %q for query", f)}
			}
			if f != filehash.FieldID {
				_spec.Node.Columns = append(_spec.Node.Columns, f)
			}
		}
	}
	if ps := fhuo.mutation.predicates; len(ps) > 0 {
		_spec.Predicate = func(selector *sql.Selector) {
			for i := range ps {
				ps[i](selector)
			}
		}
	}
	if value, ok := fhuo.mutation.Hash(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeBytes,
			Value:  value,
			Column: filehash.FieldHash,
		})
	}
	if value, ok := fhuo.mutation.Fileid(); ok {
		_spec.Fields.Set = append(_spec.Fields.Set, &sqlgraph.FieldSpec{
			Type:   field.TypeString,
			Value:  value,
			Column: filehash.FieldFileid,
		})
	}
	_node = &FileHash{config: fhuo.config}
	_spec.Assign = _node.assignValues
	_spec.ScanValues = _node.scanValues
	if err = sqlgraph.UpdateNode(ctx, fhuo.driver, _spec); err != nil {
		if _, ok := err.(*sqlgraph.NotFoundError); ok {
			err = &NotFoundError{filehash.Label}
		} else if cerr, ok := isSQLConstraintError(err); ok {
			err = cerr
		}
		return nil, err
	}
	return _node, nil
}
